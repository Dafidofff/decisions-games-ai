{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decisions Under Ignorance\n",
    "======================\n",
    "\n",
    "Shane Steinert-Threlkeld\n",
    "\n",
    "S.N.M.Steinert-Threlkeld AT uva DOT nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Motivating Example\n",
    "------\n",
    "\n",
    "I ride my bike to work in Amsterdam every day.  This morning, it looked rather gray, but was not raining.  Should I wear my waterproof pants and jacket or leave them at home?  If it does rain, I will stay dry, which is very nice.  If it doesn't rain, I will be too warm and will have to carry extra clothes around; not so nice.\n",
    "\n",
    "Weighing these pros and cons, I decide to put on the waterproof clothes, just to be safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some questions:\n",
    "* How did I go about making that decision?\n",
    "* Was it a _good_ decision?  Given my desires and values.\n",
    "    - What are my desires and values?\n",
    "    - Can they be measured?\n",
    "    \n",
    "Our primary focus will be on the second question: thus we will focus on _normative decision theory_ or _rational choice theory_.  Next time, I will say a bit about descriptive decision theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Basic Ingredients\n",
    "-----------\n",
    "\n",
    "* States: different possible ways the world could be, for all the decision-maker knows\n",
    "    - it will rain, it won't rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Acts: different options that the decision-maker can choose to do\n",
    "    - take waterproof clothes, leave them at home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Outcomes: results of the choice of the decision-maker\n",
    "    - dry and heavy packing, wet and light packing, dry and light packing\n",
    "    \n",
    "N.B.: outcomes are the _bearers of value_ for the agent.  They are determined by a state-act pair, so we will often identify them with such a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".rendered_html tbody tr td:first-child {\n",
       "    border-right: 1px solid black;\n",
       "}\n",
       "    \n",
       ".rendered_html table {\n",
       "    font-size: 28px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    ".rendered_html tbody tr td:first-child {\n",
    "    border-right: 1px solid black;\n",
    "}\n",
    "    \n",
    ".rendered_html table {\n",
    "    font-size: 28px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Putting the Ingredients Together\n",
    "-----------\n",
    "\n",
    "| act | rain | no rain |\n",
    "| ----- | ----- | ----- |\n",
    "| take clothes | dry and heavy | dry and heavy |\n",
    "| leave clothes | wet and light | dry and light |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My preferences on the outcomes:\n",
    "$$ DL \\succ DH \\succ WL$$\n",
    "We can capture this with one final ingredient: a _utility_ function\n",
    "$$u: S \\times A \\to \\mathbb{R}$$\n",
    "For today, however, all that matters is the _order_ of the outcomes, not their actual values.  (Terminology: the rules today only appeal to _ordinal_ utility.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| act | rain | no rain |\n",
    "| ----- | ----- | ----- |\n",
    "| take clothes | 1 | 1 |\n",
    "| leave clothes | 0 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Types of Decision Problems\n",
    "-----------\n",
    "\n",
    "* Decisions Under Ignorance:\n",
    "    - Multiple states of the world\n",
    "    - The agent does not know which one will obtain\n",
    "    - The agent _cannot_ assign probabilities to the states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Decisions Under Risk (next time):\n",
    "    - The agent can assign probabilities to the states\n",
    "    - Usually uses _cardinal_ utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NB: \"Decisions under Uncertainty\" is used ambiguously in the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision Problems in Python\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "decision_problem = namedtuple(\n",
    "    'decision_problem',\n",
    "    ('states', 'actions', 'utilities', 'probabilities'),\n",
    "    defaults=[None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So a `decision_problem` will be an object with named fields of the appropriate kind.  `probabilities` will default to `None`.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ride_to_work = decision_problem(\n",
    "    ('rain', 'no_rain'),\n",
    "    ('take_clothes', 'leave_clothes'),\n",
    "    [[1, 1], [0, 2]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Choice Rules\n",
    "-------\n",
    "\n",
    "* We want to assess choices as _good_ or _bad_\n",
    "* A _choice rule_ provides a criterion for so doing\n",
    "* Such a rule takes as input a decision problem $D = \\langle S, A, u, p \\rangle$ and outputs a subset of actions, those that it deems choice-worthy.  In other words, it's a function of type $$c : D \\to \\mathcal{P}(A(D))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dominance Avoidance\n",
    "---------\n",
    "\n",
    "Let's expand the motivating example.  I in fact have a third option: I could stay home instead of going to work for fear of getting wet.  But then I would miss an important meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ride_to_work = decision_problem(\n",
    "    ('rain', 'no_rain'),\n",
    "    ('take_clothes', 'leave_clothes', 'stay_home'),\n",
    "    np.array([\n",
    "        [1, 1],\n",
    "        [0, 2],\n",
    "        [-1, -1]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively: I should _not_ stay home because the meeting is too important.  More precisely: it's better to either take my clothes or leave them, regardless of whether it rains or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dominance Avoidance\n",
    "---------\n",
    "\n",
    "We can formulate our first decision rule:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{avoid_dominated}(D) = \\{ a \\in A(D) : \\lnot \\exists a' \\neq a \\text{ s.t. }& \\forall s , u(s, a') \\geq u(s, a) \\text{ and } \\\\\n",
    "& \\exists s , u(s, a') > u(s, a) \\}\n",
    "\\end{align*}\n",
    "\n",
    "(NB: this is _weak_ dominance avoidance. If we required strict inequality for all states, we would have _strong_ dominance avoidance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def avoid_dominated(decision):\n",
    "    admissible = []\n",
    "    for idx in range(len(decision.actions)):\n",
    "        compare = decision.utilities - decision.utilities[idx]\n",
    "        acts_weak = (compare >= 0).all(axis=1)\n",
    "        acts_strong = (compare > 0).any(axis=1)\n",
    "        dominated_by = acts_weak * acts_strong  # multiplication is like conjunction\n",
    "        if not dominated_by.any():\n",
    "            # dominated_by is a boolean array saying whether each action dominates the present one\n",
    "            admissible.append(decision.actions[idx])\n",
    "    return admissible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take_clothes', 'leave_clothes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avoid_dominated(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maximin\n",
    "------\n",
    "\n",
    "While dominance reasoning generally works, many decision problems have no actions that are dominated, and so avoidance does not help (i.e. $\\text{avoid_dominated}(D) = A(D)$, so every action is admissible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another intuitive thought for decisions under ignorance: since you do not know what state will obtain, make sure the worst-case scenario is the best it can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{maximin}(D) = \\text{argmax}_a \\{ \\min_s(\\{ u(s, a) \\}) \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maximin\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def maximin(decision):\n",
    "    mins = np.amin(decision.utilities, axis=1)\n",
    "    act_idxs = np.where(mins == np.amax(mins))\n",
    "    return list(np.array(decision.actions)[act_idxs])  # numpy arrays have richer indexing abilities than lists :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take_clothes']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximin(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TODO:\n",
    "\n",
    "- unintuitive consequences\n",
    "    - leximin\n",
    "- Rawls on the Veil of Ignorance\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maximax\n",
    "-----\n",
    "\n",
    "Intuitively, maximin represents cautious decision making.  But why should that be more rational than optimistic decision making?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{maximax}(D) = \\text{argmax}_a \\{ \\max_s(\\{ u(s, a) \\}) \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def maximax(decision):\n",
    "    maxs = np.amax(decision.utilities, axis=1)\n",
    "    act_idxs = np.where(maxs == np.amax(maxs))\n",
    "    return list(np.array(decision.actions)[act_idxs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leave_clothes']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximax(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimism-Pessimism\n",
    "------\n",
    "\n",
    "It seems like `maximin` and `maximax` are two ends of a spectrum of a trade-off between optimism and pessimism.\n",
    "\n",
    "We can make this precise, _if we assume that utilities are cardinal_, not merely ordinal.  (More on that next time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{hurwicz}_\\alpha(D) = \\text{argmax}_a \\{ \\alpha * \\max_s\\{u(s,a)\\} + (1-\\alpha) * \\min_s\\{u(s,a)\\} \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def hurwicz(decision, alpha=0.5):\n",
    "    maxs = np.amax(decision.utilities, axis=1)\n",
    "    mins = np.amin(decision.utilities, axis=1)\n",
    "    mixed = alpha*maxs + (1-alpha)*mins\n",
    "    act_idxs = np.where(mixed == np.amax(mixed))\n",
    "    return list(np.array(decision.actions)[act_idxs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take_clothes', 'leave_clothes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hurwicz(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TODO: objections to these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Minimax Regret\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whether or not you're pressimistic or optimistic, it seems that everyone should want to avoid _regret_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def regret(decision):\n",
    "    # the [None, :] reshapes the maxs from [2] to [1, 2]\n",
    "    return np.amax(decision.utilities, axis=0)[None, :] - decision.utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regret(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{minimax_regret}(D) = \\text{argmin}_a\\{ \\max_s \\{r(s, a)\\}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def minimax_regret(decision):\n",
    "    regrets = regret(decision)\n",
    "    maxs = np.amax(regrets, axis=1)\n",
    "    act_idxs = np.where(maxs == np.amin(maxs))\n",
    "    return list(np.array(decision.actions)[act_idxs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take_clothes', 'leave_clothes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimax_regret(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Independence of Irrelevant Alternatives\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "day_out = decision_problem(\n",
    "    ('sun', 'sprinkle', 'thunderstorm'),\n",
    "    ('play football', 'watch movie'),\n",
    "    np.array([\n",
    "        [15, 2, 6],\n",
    "        [8, 10, 9]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watch movie']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimax_regret(day_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "day_out_redux = decision_problem(\n",
    "    ('sun', 'sprinkle', 'thunderstorm'),\n",
    "    ('play football', 'watch movie', 'picnic'),\n",
    "    np.array([\n",
    "        [15, 2, 6],\n",
    "        [8, 10, 9],\n",
    "        [20, 5, 0]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['play football']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimax_regret(day_out_redux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discussion: What to make of so many divergent decision rules?\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
