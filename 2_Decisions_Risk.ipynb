{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decisions Under Risk\n",
    "======================\n",
    "\n",
    "Shane Steinert-Threlkeld\n",
    "\n",
    "S.N.M.Steinert-Threlkeld AT uva DOT nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recap\n",
    "-----\n",
    "\n",
    "* Decisions under ignorance: true state unknown, but so are the probabilities\n",
    "* Many choice rules:\n",
    "    - avoid dominance, maximin, leximin, maximax, optimism-pessimism, minimax regret\n",
    "* Every rule seemed to have pros and cons.  Is there a single _correct_ (normatively) choice rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outline\n",
    "------\n",
    "\n",
    "* Decisions under risk: probabilities known\n",
    "* Choice rule: maximize _expected_ utility\n",
    "* Justifying the MEU principle\n",
    "    - What is utility?\n",
    "    - What are the probabilities?\n",
    "* Evidential versus Causal Decision Theory\n",
    "* Problems for MEU\n",
    "* Frontiers in decision theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".rendered_html tbody tr td:first-child {\n",
       "    border-right: 1px solid black;\n",
       "}\n",
       "    \n",
       ".rendered_html table {\n",
       "    font-size: 28px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    ".rendered_html tbody tr td:first-child {\n",
    "    border-right: 1px solid black;\n",
    "}\n",
    "    \n",
    ".rendered_html table {\n",
    "    font-size: 28px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ride to Work Revisited\n",
    "----------\n",
    "\n",
    "| &#160; | rain | no rain |\n",
    "| ----- | ----- | ----- |\n",
    "| take clothes | 1 | 1 |\n",
    "| leave clothes | 0 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ride to Work Revisited\n",
    "----------\n",
    "\n",
    "| &#160; | rain ($0.7$) | no rain ($0.3$) |\n",
    "| ----- | ----- | ----- |\n",
    "| take clothes | 1 | 1 |\n",
    "| leave clothes | 0 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(NB: we now assume that these utilities are _cardinal_, representing my actual values, not merely the ordering of my preferences over the outcomes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "decision_problem = namedtuple(\n",
    "    'decision_problem',\n",
    "    ('states', 'actions', 'utilities', 'probabilities'),\n",
    "    defaults=[None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maximize Expected Utility\n",
    "---------\n",
    "\n",
    "* Observation: for each $a$, $u( \\cdot , a)$ is a _random variable_ with domain $S$ and range $\\mathbb{R}$.\n",
    "* For full generality, we assume that the function $p$ in the agent's decision problem works as follows: for each action $a$, $p_a$ is a probability distribution over the states $S$.  Intuitively, this assigns probabilities to statements of the form \"if $a$, then $s$\".  Much more on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{MEU}(D) = \\text{argmax}_a \\mathbb{E}_{p_a} u(\\cdot , a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively: we weight the utilities of the action in each outcome by how probable that outcome is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MEU in Python\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ride_to_work = decision_problem(\n",
    "    ('rain', 'no_rain'),\n",
    "    ('take_clothes', 'leave_clothes'),\n",
    "    np.array([\n",
    "        [1, 1],\n",
    "        [0, 2]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.3]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def maximize_expected_utility(decision):\n",
    "    weighted_utilities = decision.utilities * decision.probabilities  # element-wise multiplication\n",
    "    expected_utilities = np.sum(weighted_utilities, axis=1)\n",
    "    max_eu_act_idxs = np.where(expected_utilities == np.amax(expected_utilities))\n",
    "    return list(np.array(decision.actions)[max_eu_act_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take_clothes']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximize_expected_utility(ride_to_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Where `maximin` and `maximax` differed on the ignorance version of this problem because of encoding \"pessimistic\" and \"optimistic\" outlooks, `meu` relies only on the agent's degrees of belief about the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Irrelevant Alternatives are Irrelevant\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "day_out = decision_problem(\n",
    "    ('sun', 'sprinkle', 'thunderstorm'),\n",
    "    ('play football', 'watch movie'),\n",
    "    np.array([\n",
    "        [15, 2, 6],\n",
    "        [8, 10, 9]\n",
    "    ]), \n",
    "    np.array([\n",
    "        [0.2, 0.5, 0.3],\n",
    "        [0.2, 0.5, 0.3]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watch movie']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximize_expected_utility(day_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the same verdict as `minimax_regret`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "day_out_redux = decision_problem(\n",
    "    ('sun', 'sprinkle', 'thunderstorm'),\n",
    "    ('play football', 'watch movie', 'picnic'),\n",
    "    np.array([\n",
    "        [15, 2, 6],\n",
    "        [8, 10, 9],\n",
    "        [20, 5, 0]\n",
    "    ]), \n",
    "    np.array([\n",
    "        [0.2, 0.5, 0.3],\n",
    "        [0.2, 0.5, 0.3],\n",
    "        [0.2, 0.5, 0.3]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watch movie']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximize_expected_utility(day_out_redux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding the third option does not cause `meu` to favor football over the movie, contra `minimax_regret`.\n",
    "\n",
    "Exercise: explain why this holds generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Justifying the Expected Utility Principle\n",
    "----------\n",
    "\n",
    "1. It's intuitive, and provides good results in a wide range of decision problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Long-run arguments: you will be better off in the long run if you follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Grounding in rational preferences: if your preferences are rational, it is _as if_ you maximize expected utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Long-run argument\n",
    "------\n",
    "\n",
    "The (strong) law of large numbers: if $X_1 , X_2 , ...$ is an infinite sequence of independent and identically distributed (i.i.d.) random variables, then $$\\text{Pr}\\left( \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{i=1}^n X_i = \\mathbb{E}(X) \\right) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Applied to the random variable $u(\\cdot , a)$ in a decision problem $D$, this result says: if you repeatedly make a choice in the same decision problem, your average return will almost surely be the expected utility.\n",
    "\n",
    "So: you should try to maximize that quantity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some objections:\n",
    "\n",
    "* Keynes: \"In the long run, we are all dead.\"\n",
    "* While gambles arguably can, any important decisions (whether to take a job offer, or move to a new city, or...) simply cannot be repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grounding in Rational Preferences\n",
    "------\n",
    "\n",
    "* Main idea: _derive_ the MEU principle from other foundations.\n",
    "* Typically: place constraints on what it means for a set of preferences to be rational.\n",
    "* Prove a _representation theorem_: if an agent has rational preferences, they can be represented as acting in accord with MEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "von Neumann-Morgenstern\n",
    "-----\n",
    "\n",
    "A lottery can be defined as follows:\n",
    "* Any of some basic prizes are a lottery.\n",
    "* If $L_1$ and $L_2$ are lotteries and $p \\in (0, 1)$, then $pL_1/L_2$ is a lottery.\n",
    "    - Flip a coin with weight $p$: if heads, play lottery $L_1$, else $L_2$\n",
    "    \n",
    "(Can generate any finite chance situation in this way.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Revealing preferences over the basic prizes:\n",
    "\n",
    "| &#160; | 1 |\n",
    "| --- | --- |\n",
    "| $L_1$ | bitterballen |\n",
    "| $L_2$ | kaastengels |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose you (like me) have $L_1 \\preceq L_2$.  We can get more precise about how strong the preference is:\n",
    "\n",
    "| &#160; | 0.25 | 0.75 |\n",
    "| --- | --- | --- |\n",
    "| $L_1$ | bitterballen | kaastengels |\n",
    "| $L_2$ | chips | chips |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "vN-M Representation Theorem\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Axioms governing rational preferences between lotteries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Completeness: for all $L_1 , L_2$ either $L_1 \\prec L_2$, $L_1 \\succ L_2$, or $L_1 \\sim L_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Transitivity: if $L_1 \\prec L_2$ and $L_2 \\prec L_3$, then $L_1 \\prec L_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Continuity: if $L_1 \\preceq L_2 \\preceq L_3$, then there is a $p \\in [0, 1]$ such that $pL_1/L_3 \\sim L_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Independence: if $L_1 \\preceq L_2$, then for all $L_3$ and $p \\in [0, 1]$, $pL_1/L_3 \\preceq pL_2/L_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Theorem:** If an agent's preferences satisfy the four axioms, there is a function $u$ from lotteries to real numbers such that $$L_1 \\prec L_2 \\text{ iff } \\mathbb{E}[u(L_1)] < \\mathbb{E}[u(L_2)]$$\n",
    "(Moreover, this $u$ is unique up to a linear transformation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discussion of vN-M\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* What justifies the axioms on rational preference?\n",
    "    - The money pump argument for transitivity. Suppose I have the following preferences\n",
    "    \n",
    "        \\begin{align*}\n",
    "        \\text{Heineken} &\\prec \\text{IJwit} \\\\\n",
    "        \\text{IJwit} &\\prec \\text{Chouffe Bok} \\\\\n",
    "        \\text{Chouffe Bok} &\\prec \\text{Heineken}\n",
    "        \\end{align*}\n",
    "\n",
    "        and that I already have a Heineken.  You can offer me to trade it for an IJwit for 25 cents.  Then I would also pay 25 cents to trade the IJwit for a Chouffe Bok.  Finally, I would trade that for a Heineken for 25 cents.\n",
    "        \n",
    "        I'm back to where I started, just poorer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Not all choices are over lotteries!\n",
    "    - See Savage (1954), Jeffrey (1983), and Joyce (1999) for more general representation theorems in the same style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is utility?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the probabilities?\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evidential vs. Causal Decision Theory\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* What are the probabilities?\n",
    "    - Subjective degrees of belief\n",
    "    \n",
    "* Still open: _which_ probabilities?\n",
    "    - How do we specify what $p_a$ is for each act in a decision problem?\n",
    "    - It turns out that a lot hinges on the answer to this question.\n",
    "    - EDT and CDT are distinguished exactly by how they answer it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Newcomb's Problem\n",
    "-------\n",
    "\n",
    "Before you are two boxes, one transparent and one opaque.  Inside the transparent box is 1,000 euros.  You can choose to receive the contents of both boxes (\"two-box\") or only the contents of the opaque box (\"one-box\").  The opaque box was filled yesterday, its contents yesterday by a very good predictor.  If they predicted that you will two-box, the opaque box is empty.  If they predicted that you will one-box, the opaque box has 1,000,000 euros in it.  \n",
    "\n",
    "So: two-box or one-box?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| &#160; | predicted one-box | predicted two-box |\n",
    "| --- | --- | --- |\n",
    "| one-box | 1,000,000 | 0 |\n",
    "| two-box | 1,001,000 | 1,000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Two-box! It strictly dominates one-boxing.  Plus, the contents of the opaque box are already fixed.\n",
    "* One-box! That makes it much more likely that I'll get a million euros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two Views\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Evidential Decision Theory: $$p_a(s) := p(s | a)$$\n",
    "\n",
    "    This is sometimes called the \"news value\" of an action: what evidence about the state does it provide.\n",
    "    \n",
    "    Intuitively: $p(\\text{predict one-box} | \\text{one-box})$ is very high, so you should one-box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Causal Decision Theory: $$p_a(s) := p(a > s)$$\n",
    "\n",
    "    where \"$a > s$\" is the _counter-factual_ conditional \"If I had done $a$, then $s$ would have obtained.\"\n",
    "    \n",
    "    A concrete proposal: $p(a > s) := p(s | \\text{do}(a))$.\n",
    "    \n",
    "    Intuitively: $p(\\text{predict one-box} | \\text{do}(\\text{one-box})) = p(\\text{predict one-box})$, so you should two-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
